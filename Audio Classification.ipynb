{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":928025,"sourceType":"datasetVersion","datasetId":500970},{"sourceId":9140536,"sourceType":"datasetVersion","datasetId":5520474},{"sourceId":9142655,"sourceType":"datasetVersion","datasetId":5521995},{"sourceId":9142752,"sourceType":"datasetVersion","datasetId":5522078}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\nimport os\nfrom torch.utils.data import Dataset\nimport torch\nimport torchaudio\nfrom torch import nn\nfrom torch.utils.data import DataLoader\n\nfor dirname, _, filenames in os.walk('/kaggle/input/urbansound8k'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break","metadata":{"execution":{"iopub.status.busy":"2024-08-09T20:11:49.021204Z","iopub.execute_input":"2024-08-09T20:11:49.021630Z","iopub.status.idle":"2024-08-09T20:11:49.889890Z","shell.execute_reply.started":"2024-08-09T20:11:49.021599Z","shell.execute_reply":"2024-08-09T20:11:49.888697Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"/kaggle/input/urbansound8k/UrbanSound8K.csv\n/kaggle/input/urbansound8k/fold7/164797-2-0-8.wav\n/kaggle/input/urbansound8k/fold1/78360-4-0-7.wav\n/kaggle/input/urbansound8k/fold3/165039-7-3-0.wav\n/kaggle/input/urbansound8k/fold5/162432-6-7-0.wav\n/kaggle/input/urbansound8k/fold10/136558-9-1-21.wav\n/kaggle/input/urbansound8k/fold9/13579-2-0-48.wav\n/kaggle/input/urbansound8k/fold8/74677-0-0-116.wav\n/kaggle/input/urbansound8k/fold4/171305-7-14-0.wav\n/kaggle/input/urbansound8k/fold2/76086-4-0-58.wav\n/kaggle/input/urbansound8k/fold6/107842-4-2-4.wav\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torchsummary\nfrom torchsummary import summary","metadata":{"execution":{"iopub.status.busy":"2024-08-09T18:27:03.775711Z","iopub.execute_input":"2024-08-09T18:27:03.776214Z","iopub.status.idle":"2024-08-09T18:27:17.074150Z","shell.execute_reply.started":"2024-08-09T18:27:03.776184Z","shell.execute_reply":"2024-08-09T18:27:17.072838Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"class CNNNetwork(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        # 4 conv blocks / flatten / linear / softmax\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=1,\n                out_channels=16,\n                kernel_size=3,\n                stride=1,\n                padding=2\n            ),\n            nn.BatchNorm2d(16),  \n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=16,\n                out_channels=32,\n                kernel_size=3,\n                stride=1,\n                padding=2\n            ),\n            nn.BatchNorm2d(32),  # Batch Normalization\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n        )\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=32,\n                out_channels=64,\n                kernel_size=3,\n                stride=1,\n                padding=2\n            ),\n            nn.BatchNorm2d(64),  # Batch Normalization\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n        )\n        self.conv4 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=64,\n                out_channels=128,\n                kernel_size=3,\n                stride=1,\n                padding=2\n            ),\n            nn.BatchNorm2d(128), # Batch Normalization\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n        )\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(128 * 5 * 4, 512)  # Adjusts size for fc1\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 10)\n        self.dropout = nn.Dropout(p=0.4)  # Dropout before final layer\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, input_data):\n        x = self.conv1(input_data)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = nn.ReLU()(x)  # ReLU activation function for hidden layers\n        x = self.fc2(x)\n        x = nn.ReLU()(x)  # ReLU activation function for hidden layers\n        x = self.dropout(x)  # Applies Dropout\n        logits = self.fc3(x)\n        predictions = self.softmax(logits)\n        return predictions\n\nif __name__ == \"__main__\":\n    cnn = CNNNetwork()\n    summary(cnn, (1, 64, 44))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-09T18:27:18.091530Z","iopub.execute_input":"2024-08-09T18:27:18.092543Z","iopub.status.idle":"2024-08-09T18:27:18.297727Z","shell.execute_reply.started":"2024-08-09T18:27:18.092504Z","shell.execute_reply":"2024-08-09T18:27:18.296641Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 16, 66, 46]             160\n       BatchNorm2d-2           [-1, 16, 66, 46]              32\n              ReLU-3           [-1, 16, 66, 46]               0\n         MaxPool2d-4           [-1, 16, 33, 23]               0\n            Conv2d-5           [-1, 32, 35, 25]           4,640\n       BatchNorm2d-6           [-1, 32, 35, 25]              64\n              ReLU-7           [-1, 32, 35, 25]               0\n         MaxPool2d-8           [-1, 32, 17, 12]               0\n            Conv2d-9           [-1, 64, 19, 14]          18,496\n      BatchNorm2d-10           [-1, 64, 19, 14]             128\n             ReLU-11           [-1, 64, 19, 14]               0\n        MaxPool2d-12             [-1, 64, 9, 7]               0\n           Conv2d-13           [-1, 128, 11, 9]          73,856\n      BatchNorm2d-14           [-1, 128, 11, 9]             256\n             ReLU-15           [-1, 128, 11, 9]               0\n        MaxPool2d-16            [-1, 128, 5, 4]               0\n          Flatten-17                 [-1, 2560]               0\n           Linear-18                  [-1, 512]       1,311,232\n           Linear-19                  [-1, 256]         131,328\n          Dropout-20                  [-1, 256]               0\n           Linear-21                   [-1, 10]           2,570\n          Softmax-22                   [-1, 10]               0\n================================================================\nTotal params: 1,542,762\nTrainable params: 1,542,762\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 2.65\nParams size (MB): 5.89\nEstimated Total Size (MB): 8.55\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"BATCH_SIZE = 128\nEPOCHS = 250\nLEARNING_RATE = 0.001\n\nANNOTATIONS_FILE = \"/kaggle/input/urbansound8k/UrbanSound8K.csv\"\nAUDIO_DIR = \"/kaggle/input/urbansound8k\"\nSAMPLE_RATE = 22050\nNUM_SAMPLES = 22050","metadata":{"execution":{"iopub.status.busy":"2024-08-09T18:27:46.168861Z","iopub.execute_input":"2024-08-09T18:27:46.169243Z","iopub.status.idle":"2024-08-09T18:27:46.174528Z","shell.execute_reply.started":"2024-08-09T18:27:46.169212Z","shell.execute_reply":"2024-08-09T18:27:46.173348Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class UrbanSoundDataset(Dataset):\n\n    def __init__(self,\n                 annotations_file,\n                 audio_dir,\n                 transformation,\n                 target_sample_rate,\n                 num_samples,\n                 device):\n        self.annotations = pd.read_csv(annotations_file)\n        self.annotations = self.annotations.iloc[:6990]\n        self.audio_dir = audio_dir\n        self.device = device\n        self.transformation = transformation.to(self.device)\n        self.target_sample_rate = target_sample_rate\n        self.num_samples = num_samples\n\n    def __len__(self):\n         return len(self.annotations)\n\n    def __getitem__(self, index):\n        audio_sample_path = self._get_audio_sample_path(index)\n        label = self._get_audio_sample_label(index)\n        signal, sr = torchaudio.load(audio_sample_path)\n        signal = signal.to(self.device)\n        signal = self._resample_if_necessary(signal, sr)\n        signal = self._mix_down_if_necessary(signal)\n        signal = self._cut_if_necessary(signal)\n        signal = self._right_pad_if_necessary(signal)\n        signal = self.transformation(signal)  # Ensures transformation is on the same device\n        return signal, label\n\n    def _cut_if_necessary(self, signal):\n        if signal.shape[1] > self.num_samples:\n            signal = signal[:, :self.num_samples]\n        return signal\n\n    def _right_pad_if_necessary(self, signal):\n        length_signal = signal.shape[1]\n        if length_signal < self.num_samples:\n            num_missing_samples = self.num_samples - length_signal\n            last_dim_padding = (0, num_missing_samples)\n            signal = torch.nn.functional.pad(signal, last_dim_padding)\n        return signal\n\n    def _resample_if_necessary(self, signal, sr):\n        if sr != self.target_sample_rate:\n            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate).to(self.device)\n            signal = resampler(signal)\n        return signal\n\n    def _mix_down_if_necessary(self, signal):\n        if signal.shape[0] > 1:\n            signal = torch.mean(signal, dim=0, keepdim=True)\n        return signal\n\n    def _get_audio_sample_path(self, index):\n        fold = f\"fold{self.annotations.iloc[index, 5]}\"\n        path = os.path.join(self.audio_dir, fold, self.annotations.iloc[index, 0])\n        return path\n\n    def _get_audio_sample_label(self, index):\n        return self.annotations.iloc[index, 6]\n\nif __name__ == \"__main__\":\n    ANNOTATIONS_FILE = \"/kaggle/input/urbansound8k/UrbanSound8K.csv\"\n    AUDIO_DIR = \"/kaggle/input/urbansound8k\"\n    SAMPLE_RATE = 22050\n    NUM_SAMPLES = 22050\n\n    device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device {device}\")\n\n    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n        sample_rate=SAMPLE_RATE,\n        n_fft=1024,\n        hop_length=512,\n        n_mels=64\n        ).to(device)  \n    \n    usd = UrbanSoundDataset(ANNOTATIONS_FILE,\n                            AUDIO_DIR,\n                            mel_spectrogram,\n                            SAMPLE_RATE,\n                            NUM_SAMPLES,\n                            device)\n    print(f\"There are {len(usd)} samples in the dataset.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-09T20:13:28.288815Z","iopub.execute_input":"2024-08-09T20:13:28.289276Z","iopub.status.idle":"2024-08-09T20:13:28.295741Z","shell.execute_reply.started":"2024-08-09T20:13:28.289244Z","shell.execute_reply":"2024-08-09T20:13:28.294469Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Using device cuda\nThere are 6990 samples in the dataset.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training block\n\ndef create_data_loader(train_data, batch_size):\n    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n    return train_dataloader\n\ndef train_single_epoch(model, data_loader, loss_fn, optimizer, device):\n    running_loss = 0.0\n    correct_predictions = 0\n    total_samples = 0\n    \n    model.train()  # Sets the model to training mode\n\n    for inputs, targets in data_loader:\n        inputs, targets = inputs.to(device), targets.to(device)\n\n        # Forward pass: computes predicted outputs by passing inputs to the model\n        predictions = model(inputs)\n        loss = loss_fn(predictions, targets)\n\n        # Backward pass: computes gradient of the loss with respect to model parameters\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Accumulates loss\n        running_loss += loss.item()\n\n        # accuracy\n        _, predicted_labels = torch.max(predictions, 1)\n        correct_predictions += (predicted_labels == targets).sum().item()\n        total_samples += targets.size(0)\n\n    # Calculates the average loss over the epoch\n    average_loss = running_loss / len(data_loader)\n    \n    # Calculates accuracy\n    accuracy = correct_predictions / total_samples * 100\n\n    print(f\"Loss: {average_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n\ndef train(model, data_loader, loss_fn, optimiser, device, epochs):\n    for i in range(epochs):\n        print(f\"Epoch {i+1}\")\n        train_single_epoch(model, data_loader, loss_fn, optimiser, device)\n        if (i + 1) % 20 == 0:\n            Data_Snapshot = f'/kaggle/working/cnnnet_epoch_{i+1}.pth'\n            torch.save(model.state_dict(), Data_Snapshot)\n            print(f\" saved at {Data_Snapshot}\")\n        print(\"---------------------------\")\n    print(\"Finished training\")\n\nif __name__ == \"__main__\":\n    if torch.cuda.is_available():\n        device = \"cuda\"\n    else:\n        device = \"cpu\"\n    print(f\"Using {device}\")\n\n    # instantiating our dataset object and create data loader\n    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n        sample_rate=SAMPLE_RATE,\n        n_fft=1024,\n        hop_length=512,\n        n_mels=64\n    )\n\n    usd = UrbanSoundDataset(ANNOTATIONS_FILE,\n                            AUDIO_DIR,\n                            mel_spectrogram,\n                            SAMPLE_RATE,\n                            NUM_SAMPLES,\n                            device)\n    \n    train_dataloader = create_data_loader(usd, BATCH_SIZE)\n\n    # constructs model and assigns it to device\n    cnn = CNNNetwork().to(device)\n    print(cnn)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-09T19:43:51.800033Z","iopub.execute_input":"2024-08-09T19:43:51.800462Z","iopub.status.idle":"2024-08-09T19:43:51.814209Z","shell.execute_reply.started":"2024-08-09T19:43:51.800424Z","shell.execute_reply":"2024-08-09T19:43:51.812957Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"31.3s 8821 Epoch 1\n241.6s 8822 Loss: 2.2735, Accuracy: 16.45%\n241.6s 8823 ---------------------------\n241.6s 8824 Epoch 2\n350.1s 8825 Loss: 2.2567, Accuracy: 17.81%\n350.1s 8826 ---------------------------\n350.1s 8827 Epoch 3\n458.7s 8828 Loss: 2.2384, Accuracy: 21.10%\n458.7s 8829 ---------------------------\n458.7s 8830 Epoch 4\n567.2s 8831 Loss: 2.2286, Accuracy: 22.39%\n567.2s 8832 ---------------------------\n567.2s 8833 Epoch 5\n675.9s 8834 Loss: 2.2156, Accuracy: 23.92%\n675.9s 8835 ---------------------------\n675.9s 8836 Epoch 6\n784.8s 8837 Loss: 2.2109, Accuracy: 24.48%\n784.8s 8838 ---------------------------\n784.8s 8839 Epoch 7\n894.1s 8840 Loss: 2.2001, Accuracy: 25.36%\n894.1s 8841 ---------------------------\n894.1s 8842 Epoch 8\n1003.4s 8843 Loss: 2.2015, Accuracy: 24.28%\n1003.4s 8844 ---------------------------\n1003.4s 8845 Epoch 9\n1113.0s 8846 Loss: 2.1853, Accuracy: 26.05%\n1113.0s 8847 ---------------------------\n1113.0s 8848 Epoch 10\n1221.4s 8849 Loss: 2.1683, Accuracy: 28.51%\n1221.4s 8850 ---------------------------\n1221.4s 8851 Epoch 11\n1330.9s 8852 Loss: 2.1651, Accuracy: 28.34%\n1330.9s 8853 ---------------------------\n1330.9s 8854 Epoch 12\n1440.8s 8855 Loss: 2.1527, Accuracy: 29.91%\n1440.8s 8856 ---------------------------\n1440.8s 8857 Epoch 13\n1550.4s 8858 Loss: 2.1465, Accuracy: 30.44%\n1550.4s 8859 ---------------------------\n1550.4s 8860 Epoch 14\n1659.4s 8861 Loss: 2.1373, Accuracy: 31.73%\n1659.4s 8862 ---------------------------\n1659.4s 8863 Epoch 15\n1768.3s 8864 Loss: 2.1441, Accuracy: 30.17%\n1768.3s 8865 ---------------------------\n1768.3s 8866 Epoch 16\n1877.8s 8867 Loss: 2.1319, Accuracy: 31.79%\n1877.8s 8868 ---------------------------\n1877.8s 8869 Epoch 17\n1987.5s 8870 Loss: 2.1340, Accuracy: 31.26%\n1987.5s 8871 ---------------------------\n1987.5s 8872 Epoch 18\n2098.5s 8873 Loss: 2.1323, Accuracy: 31.76%\n2098.5s 8874 ---------------------------\n2098.5s 8875 Epoch 19\n2209.1s 8876 Loss: 2.1292, Accuracy: 32.22%\n2209.1s 8877 ---------------------------\n2209.1s 8878 Epoch 20\n2317.9s 8879 Loss: 2.1254, Accuracy: 32.33%\n2317.9s 8880 saved at /kaggle/working/cnnnet_epoch_20.pth\n2317.9s 8881 ---------------------------\n2317.9s 8882 Epoch 21\n2427.2s 8883 Loss: 2.1056, Accuracy: 35.26%\n2427.2s 8884 ---------------------------\n2427.2s 8885 Epoch 22\n2535.3s 8886 Loss: 2.1083, Accuracy: 34.71%\n2535.3s 8887 ---------------------------\n2535.3s 8888 Epoch 23\n2645.1s 8889 Loss: 2.1084, Accuracy: 34.26%\n2645.1s 8890 ---------------------------\n2645.1s 8891 Epoch 24\n2755.0s 8892 Loss: 2.0952, Accuracy: 35.54%\n2755.0s 8893 ---------------------------\n2755.0s 8894 Epoch 25\n2864.3s 8895 Loss: 2.0815, Accuracy: 37.32%\n2864.3s 8896 ---------------------------\n2864.3s 8897 Epoch 26\n2973.7s 8898 Loss: 2.0705, Accuracy: 38.25%\n2973.7s 8899 ---------------------------\n2973.7s 8900 Epoch 27\n3083.0s 8901 Loss: 2.0778, Accuracy: 37.45%\n3083.0s 8902 ---------------------------\n3083.0s 8903 Epoch 28\n3192.2s 8904 Loss: 2.0857, Accuracy: 37.05%\n3192.2s 8905 ---------------------------\n3192.2s 8906 Epoch 29\n3302.8s 8907 Loss: 2.0802, Accuracy: 37.53%\n3302.8s 8908 ---------------------------\n3302.8s 8909 Epoch 30\n3412.6s 8910 Loss: 2.0642, Accuracy: 38.87%\n3412.6s 8911 ---------------------------\n3412.6s 8912 Epoch 31\n3521.3s 8913 Loss: 2.0525, Accuracy: 40.04%\n3521.3s 8914 ---------------------------\n3521.3s 8915 Epoch 32\n3630.7s 8916 Loss: 2.0502, Accuracy: 40.66%\n3630.7s 8917 ---------------------------\n3630.7s 8918 Epoch 33\n3740.4s 8919 Loss: 2.0439, Accuracy: 41.12%\n3740.4s 8920 ---------------------------\n3740.4s 8921 Epoch 34\n3851.4s 8922 Loss: 2.0359, Accuracy: 42.20%\n3851.4s 8923 ---------------------------\n3851.4s 8924 Epoch 35\n3962.1s 8925 Loss: 2.0373, Accuracy: 41.60%\n3962.1s 8926 ---------------------------\n3962.1s 8927 Epoch 36\n4072.9s 8928 Loss: 2.0205, Accuracy: 43.89%\n4072.9s 8929 ---------------------------\n4072.9s 8930 Epoch 37\n4181.3s 8931 Loss: 2.0226, Accuracy: 43.91%\n4181.3s 8932 ---------------------------\n4181.3s 8933 Epoch 38\n4290.2s 8934 Loss: 2.0355, Accuracy: 42.45%\n4290.2s 8935 ---------------------------\n4290.2s 8936 Epoch 39\n4399.6s 8937 Loss: 2.0283, Accuracy: 43.29%\n4399.6s 8938 ---------------------------\n4399.6s 8939 Epoch 40\n4507.9s 8940 Loss: 2.0128, Accuracy: 44.32%\n4507.9s 8941 saved at /kaggle/working/cnnnet_epoch_40.pth\n4507.9s 8942 ---------------------------\n4507.9s 8943 Epoch 41\n4616.4s 8944 Loss: 2.0227, Accuracy: 43.25%\n4616.4s 8945 ---------------------------\n4616.4s 8946 Epoch 42\n4725.3s 8947 Loss: 2.0183, Accuracy: 43.79%\n4725.3s 8948 ---------------------------\n4725.3s 8949 Epoch 43\n4834.2s 8950 Loss: 1.9923, Accuracy: 46.75%\n4834.2s 8951 ---------------------------\n4834.2s 8952 Epoch 44\n4943.4s 8953 Loss: 1.9768, Accuracy: 48.27%\n4943.4s 8954 ---------------------------\n4943.4s 8955 Epoch 45\n5053.3s 8956 Loss: 1.9764, Accuracy: 48.20%\n5053.3s 8957 ---------------------------\n5053.3s 8958 Epoch 46\n5163.3s 8959 Loss: 1.9878, Accuracy: 47.40%\n5163.3s 8960 ---------------------------\n5163.3s 8961 Epoch 47\n5272.5s 8962 Loss: 1.9507, Accuracy: 51.03%\n5272.5s 8963 ---------------------------\n5272.5s 8964 Epoch 48\n5381.3s 8965 Loss: 1.9424, Accuracy: 51.69%\n5381.3s 8966 ---------------------------\n5381.3s 8967 Epoch 49\n5493.1s 8968 Loss: 1.9544, Accuracy: 50.50%\n5493.1s 8969 ---------------------------\n5493.1s 8970 Epoch 50\n5604.6s 8971 Loss: 1.9971, Accuracy: 46.01%\n5604.6s 8972 ---------------------------\n5604.6s 8973 Epoch 51\n5714.1s 8974 Loss: 1.9511, Accuracy: 50.84%\n5714.1s 8975 ---------------------------\n5714.1s 8976 Epoch 52\n5822.7s 8977 Loss: 1.9460, Accuracy: 51.24%\n5822.7s 8978 ---------------------------\n5822.7s 8979 Epoch 53\n5931.1s 8980 Loss: 1.9384, Accuracy: 51.96%\n5931.1s 8981 ---------------------------\n5931.1s 8982 Epoch 54\n6039.6s 8983 Loss: 1.9179, Accuracy: 53.98%\n6039.6s 8984 ---------------------------\n6039.6s 8985 Epoch 55\n6149.0s 8986 Loss: 1.9098, Accuracy: 54.86%\n6149.0s 8987 ---------------------------\n6149.0s 8988 Epoch 56\n6261.5s 8989 Loss: 1.9103, Accuracy: 54.96%\n6261.5s 8990 ---------------------------\n6261.5s 8991 Epoch 57\n6372.6s 8992 Loss: 1.9036, Accuracy: 55.58%\n6372.6s 8993 ---------------------------\n6372.6s 8994 Epoch 58\n6484.2s 8995 Loss: 1.9011, Accuracy: 55.68%\n6484.2s 8996 ---------------------------\n6484.2s 8997 Epoch 59\n6595.5s 8998 Loss: 1.8765, Accuracy: 58.35%\n6595.5s 8999 ---------------------------\n6595.5s 9000 Epoch 60\n6706.5s 9001 Loss: 1.8698, Accuracy: 58.98%\n6706.5s 9002 saved at /kaggle/working/cnnnet_epoch_60.pth\n6706.5s 9003 ---------------------------\n6706.5s 9004 Epoch 61\n6817.9s 9005 Loss: 1.8698, Accuracy: 59.08%\n6817.9s 9006 ---------------------------\n6817.9s 9007 Epoch 62\n6928.8s 9008 Loss: 1.8742, Accuracy: 58.61%\n6928.8s 9009 ---------------------------\n6928.8s 9010 Epoch 63\n7038.1s 9011 Loss: 1.8662, Accuracy: 59.30%\n7038.1s 9012 ---------------------------\n7038.1s 9013 Epoch 64\n7147.8s 9014 Loss: 1.8711, Accuracy: 58.86%\n7147.8s 9015 ---------------------------\n7147.8s 9016 Epoch 65\n7256.8s 9017 Loss: 1.8655, Accuracy: 59.53%\n7256.8s 9018 ---------------------------\n7256.8s 9019 Epoch 66\n7366.3s 9020 Loss: 1.8566, Accuracy: 60.24%\n7366.3s 9021 ---------------------------\n7366.3s 9022 Epoch 67\n7476.1s 9023 Loss: 1.8558, Accuracy: 60.23%\n7476.1s 9024 ---------------------------\n7476.1s 9025 Epoch 68\n7585.8s 9026 Loss: 1.8685, Accuracy: 59.16%\n7585.8s 9027 ---------------------------\n7585.8s 9028 Epoch 69\n7695.5s 9029 Loss: 1.8825, Accuracy: 57.54%\n7695.5s 9030 ---------------------------\n7695.5s 9031 Epoch 70\n7805.5s 9032 Loss: 1.8606, Accuracy: 59.83%\n7805.5s 9033 ---------------------------\n7805.5s 9034 Epoch 71\n7916.6s 9035 Loss: 1.8509, Accuracy: 60.86%\n7916.6s 9036 ---------------------------\n7916.6s 9037 Epoch 72\n8026.0s 9038 Loss: 1.8459, Accuracy: 61.33%\n8026.0s 9039 ---------------------------\n8026.0s 9040 Epoch 73\n8135.2s 9041 Loss: 1.8494, Accuracy: 60.94%\n8135.2s 9042 ---------------------------\n8135.2s 9043 Epoch 74\n8244.3s 9044 Loss: 1.8542, Accuracy: 60.49%\n8244.3s 9045 ---------------------------\n8244.3s 9046 Epoch 75\n8354.5s 9047 Loss: 1.8700, Accuracy: 58.93%\n8354.5s 9048 ---------------------------\n8354.5s 9049 Epoch 76\n8464.0s 9050 Loss: 1.8556, Accuracy: 60.33%\n8464.0s 9051 ---------------------------\n8464.0s 9052 Epoch 77\n8573.2s 9053 Loss: 1.8546, Accuracy: 60.43%\n8573.2s 9054 ---------------------------\n8573.2s 9055 Epoch 78\n8684.1s 9056 Loss: 1.8335, Accuracy: 62.63%\n8684.1s 9057 ---------------------------\n8684.1s 9058 Epoch 79\n8793.4s 9059 Loss: 1.8144, Accuracy: 64.46%\n8793.4s 9060 ---------------------------\n8793.4s 9061 Epoch 80\n8903.0s 9062 Loss: 1.8256, Accuracy: 63.35%\n8903.0s 9063 saved at /kaggle/working/cnnnet_epoch_80.pth\n8903.0s 9064 ---------------------------\n8903.0s 9065 Epoch 81\n9011.9s 9066 Loss: 1.8305, Accuracy: 62.83%\n9011.9s 9067 ---------------------------\n9011.9s 9068 Epoch 82\n9121.2s 9069 Loss: 1.8271, Accuracy: 63.20%\n9121.2s 9070 ---------------------------\n9121.2s 9071 Epoch 83\n9231.9s 9072 Loss: 1.8310, Accuracy: 63.09%\n9231.9s 9073 ---------------------------\n9231.9s 9074 Epoch 84\n9341.9s 9075 Loss: 1.8292, Accuracy: 63.00%\n9341.9s 9076 ---------------------------\n9341.9s 9077 Epoch 85\n9451.4s 9078 Loss: 1.8238, Accuracy: 63.65%\n9451.4s 9079 ---------------------------\n9451.4s 9080 Epoch 86\n9561.3s 9081 Loss: 1.8130, Accuracy: 64.51%\n9561.3s 9082 ---------------------------\n9561.3s 9083 Epoch 87\n9670.9s 9084 Loss: 1.7976, Accuracy: 66.21%\n9670.9s 9085 ---------------------------\n9670.9s 9086 Epoch 88\n9781.6s 9087 Loss: 1.7790, Accuracy: 68.13%\n9781.6s 9088 ---------------------------\n9781.6s 9089 Epoch 89\n9892.3s 9090 Loss: 1.7778, Accuracy: 68.21%\n9892.3s 9091 ---------------------------\n9892.3s 9092 Epoch 90\n10004.4s 9093 Loss: 1.7824, Accuracy: 67.77%\n10004.4s 9094 ---------------------------\n10004.4s 9095 Epoch 91\n10117.2s 9096 Loss: 1.8059, Accuracy: 65.41%\n10117.2s 9097 ---------------------------\n10117.2s 9098 Epoch 92\n10227.6s 9099 Loss: 1.8088, Accuracy: 65.04%\n10227.6s 9100 ---------------------------\n10227.6s 9101 Epoch 93\n10336.8s 9102 Loss: 1.7805, Accuracy: 67.87%\n10336.8s 9103 ---------------------------\n10336.8s 9104 Epoch 94\n10446.8s 9105 Loss: 1.7772, Accuracy: 68.11%\n10446.8s 9106 ---------------------------\n10446.8s 9107 Epoch 95\n10555.6s 9108 Loss: 1.7545, Accuracy: 70.53%\n10555.6s 9109 ---------------------------\n10555.6s 9110 Epoch 96\n10664.1s 9111 Loss: 1.7511, Accuracy: 70.86%\n10664.1s 9112 ---------------------------\n10664.1s 9113 Epoch 97\n10772.8s 9114 Loss: 1.7387, Accuracy: 72.23%\n10772.8s 9115 ---------------------------\n10772.8s 9116 Epoch 98\n10881.7s 9117 Loss: 1.7392, Accuracy: 72.02%\n10881.7s 9118 ---------------------------\n10881.7s 9119 Epoch 99\n10991.0s 9120 Loss: 1.7436, Accuracy: 71.60%\n10991.0s 9121 ---------------------------\n10991.0s 9122 Epoch 100\n11100.9s 9123 Loss: 1.7322, Accuracy: 72.88%\n11100.9s 9124 saved at /kaggle/working/cnnnet_epoch_100.pth\n11100.9s 9125 ---------------------------\n11100.9s 9126 Epoch 101\n11210.8s 9127 Loss: 1.7338, Accuracy: 72.65%\n11210.8s 9128 ---------------------------\n11210.8s 9129 Epoch 102\n11323.0s 9130 Loss: 1.7308, Accuracy: 72.98%\n11323.0s 9131 ---------------------------\n11323.0s 9132 Epoch 103\n11434.4s 9133 Loss: 1.7453, Accuracy: 71.59%\n11434.4s 9134 ---------------------------\n11434.4s 9135 Epoch 104\n11546.0s 9136 Loss: 1.7645, Accuracy: 69.54%\n11546.0s 9137 ---------------------------\n11546.0s 9138 Epoch 105\n11657.8s 9139 Loss: 1.7577, Accuracy: 70.29%\n11657.8s 9140 ---------------------------\n11657.8s 9141 Epoch 106\n11768.4s 9142 Loss: 1.7384, Accuracy: 72.13%\n11768.4s 9143 ---------------------------\n11768.4s 9144 Epoch 107\n11880.1s 9145 Loss: 1.7295, Accuracy: 73.00%\n11880.1s 9146 ---------------------------\n11880.1s 9147 Epoch 108\n11992.4s 9148 Loss: 1.7166, Accuracy: 74.42%\n11992.4s 9149 ---------------------------\n11992.4s 9150 Epoch 109\n12102.1s 9151 Loss: 1.7123, Accuracy: 74.84%\n12102.1s 9152 ---------------------------\n12102.1s 9153 Epoch 110\n12212.3s 9154 Loss: 1.7265, Accuracy: 73.43%\n12212.3s 9155 ---------------------------\n12212.3s 9156 Epoch 111\n12323.9s 9157 Loss: 1.7210, Accuracy: 74.11%\n12323.9s 9158 ---------------------------\n12323.9s 9159 Epoch 112\n12432.5s 9160 Loss: 1.7242, Accuracy: 73.48%\n12432.5s 9161 ---------------------------\n12432.5s 9162 Epoch 113\n12541.2s 9163 Loss: 1.7350, Accuracy: 72.53%\n12541.2s 9164 ---------------------------\n12541.2s 9165 Epoch 114\n12650.2s 9166 Loss: 1.7217, Accuracy: 73.73%\n12650.2s 9167 ---------------------------\n12650.2s 9168 Epoch 115\n12758.9s 9169 Loss: 1.7179, Accuracy: 74.25%\n12758.9s 9170 ---------------------------\n12758.9s 9171 Epoch 116\n12868.9s 9172 Loss: 1.7068, Accuracy: 75.36%\n12868.9s 9173 ---------------------------\n12868.9s 9174 Epoch 117\n12978.9s 9175 Loss: 1.6908, Accuracy: 77.01%\n12978.9s 9176 ---------------------------\n12978.9s 9177 Epoch 118\n13087.5s 9178 Loss: 1.6809, Accuracy: 77.98%\n13087.5s 9179 ---------------------------\n13087.5s 9180 Epoch 119\n13195.7s 9181 Loss: 1.6792, Accuracy: 78.23%\n13195.7s 9182 ---------------------------\n13195.7s 9183 Epoch 120\n13303.9s 9184 Loss: 1.6869, Accuracy: 77.27%\n13303.9s 9185 saved at /kaggle/working/cnnnet_epoch_120.pth\n13303.9s 9186 ---------------------------\n13303.9s 9187 Epoch 121\n13412.6s 9188 Loss: 1.6977, Accuracy: 76.37%\n13412.6s 9189 ---------------------------\n13412.6s 9190 Epoch 122\n13521.0s 9191 Loss: 1.6933, Accuracy: 76.75%\n13521.0s 9192 ---------------------------\n13521.0s 9193 Epoch 123\n13629.5s 9194 Loss: 1.6872, Accuracy: 77.28%\n13629.5s 9195 ---------------------------\n13629.5s 9196 Epoch 124\n13738.2s 9197 Loss: 1.7032, Accuracy: 75.79%\n13738.2s 9198 ---------------------------\n13738.2s 9199 Epoch 125\n13847.5s 9200 Loss: 1.6830, Accuracy: 77.83%\n13847.5s 9201 ---------------------------\n13847.5s 9202 Epoch 126\n13956.4s 9203 Loss: 1.6780, Accuracy: 78.21%\n13956.4s 9204 ---------------------------\n13956.4s 9205 Epoch 127\n14065.3s 9206 Loss: 1.6834, Accuracy: 77.73%\n14065.3s 9207 ---------------------------\n14065.3s 9208 Epoch 128\n14175.3s 9209 Loss: 1.6765, Accuracy: 78.45%\n14175.3s 9210 ---------------------------\n14175.3s 9211 Epoch 129\n14283.4s 9212 Loss: 1.6740, Accuracy: 78.67%\n14283.4s 9213 ---------------------------\n14283.4s 9214 Epoch 130\n14391.9s 9215 Loss: 1.6726, Accuracy: 78.86%\n14391.9s 9216 ---------------------------\n14391.9s 9217 Epoch 131\n14499.7s 9218 Loss: 1.6581, Accuracy: 80.30%\n14499.7s 9219 ---------------------------\n14499.7s 9220 Epoch 132\n14608.2s 9221 Loss: 1.6556, Accuracy: 80.43%\n14608.2s 9222 ---------------------------\n14608.2s 9223 Epoch 133\n14717.2s 9224 Loss: 1.6633, Accuracy: 79.63%\n14717.2s 9225 ---------------------------\n14717.2s 9226 Epoch 134\n14827.0s 9227 Loss: 1.6740, Accuracy: 78.63%\n14827.0s 9228 ---------------------------\n14827.0s 9229 Epoch 135\n14935.9s 9230 Loss: 1.7195, Accuracy: 74.11%\n14935.9s 9231 ---------------------------\n14935.9s 9232 Epoch 136\n15044.3s 9233 Loss: 1.6833, Accuracy: 77.75%\n15044.3s 9234 ---------------------------\n15044.3s 9235 Epoch 137\n15152.9s 9236 Loss: 1.6653, Accuracy: 79.48%\n15152.9s 9237 ---------------------------\n15152.9s 9238 Epoch 138\n15262.0s 9239 Loss: 1.6600, Accuracy: 80.11%\n15262.0s 9240 ---------------------------\n15262.0s 9241 Epoch 139\n15370.5s 9242 Loss: 1.6574, Accuracy: 80.36%\n15370.5s 9243 ---------------------------\n15370.5s 9244 Epoch 140\n15478.9s 9245 Loss: 1.6524, Accuracy: 80.74%\n15478.9s 9246 saved at /kaggle/working/cnnnet_epoch_140.pth\n15478.9s 9247 ---------------------------\n15478.9s 9248 Epoch 141\n15587.0s 9249 Loss: 1.6632, Accuracy: 79.76%\n15587.0s 9250 ---------------------------\n15587.0s 9251 Epoch 142\n15695.5s 9252 Loss: 1.6598, Accuracy: 80.00%\n15695.5s 9253 ---------------------------\n15695.5s 9254 Epoch 143\n15803.4s 9255 Loss: 1.6549, Accuracy: 80.57%\n15803.4s 9256 ---------------------------\n15803.4s 9257 Epoch 144\n15912.9s 9258 Loss: 1.6407, Accuracy: 82.07%\n15912.9s 9259 ---------------------------\n15912.9s 9260 Epoch 145\n16022.0s 9261 Loss: 1.6429, Accuracy: 81.72%\n16022.0s 9262 ---------------------------\n16022.0s 9263 Epoch 146\n16130.5s 9264 Loss: 1.6440, Accuracy: 81.69%\n16130.5s 9265 ---------------------------\n16130.5s 9266 Epoch 147\n16239.1s 9267 Loss: 1.6389, Accuracy: 82.19%\n16239.1s 9268 ---------------------------\n16239.1s 9269 Epoch 148\n16348.5s 9270 Loss: 1.6366, Accuracy: 82.45%\n16348.5s 9271 ---------------------------\n16348.5s 9272 Epoch 149\n16458.0s 9273 Loss: 1.6566, Accuracy: 80.34%\n16458.0s 9274 ---------------------------\n16458.0s 9275 Epoch 150\n16567.8s 9276 Loss: 1.6415, Accuracy: 81.93%\n16567.8s 9277 ---------------------------\n16567.8s 9278 Epoch 151\n16679.6s 9279 Loss: 1.6516, Accuracy: 80.92%\n16679.6s 9280 ---------------------------\n16679.6s 9281 Epoch 152\n16791.0s 9282 Loss: 1.6384, Accuracy: 82.27%\n16791.0s 9283 ---------------------------\n16791.0s 9284 Epoch 153\n16901.0s 9285 Loss: 1.6323, Accuracy: 82.88%\n16901.0s 9286 ---------------------------\n16901.0s 9287 Epoch 154\n17011.8s 9288 Loss: 1.6283, Accuracy: 83.20%\n17011.8s 9289 ---------------------------\n17011.8s 9290 Epoch 155\n17122.1s 9291 Loss: 1.6250, Accuracy: 83.56%\n17122.1s 9292 ---------------------------\n17122.1s 9293 Epoch 156\n17231.4s 9294 Loss: 1.6302, Accuracy: 83.02%\n17231.4s 9295 ---------------------------\n17231.4s 9296 Epoch 157\n17340.3s 9297 Loss: 1.6299, Accuracy: 83.12%\n17340.3s 9298 ---------------------------\n17340.3s 9299 Epoch 158\n17449.4s 9300 Loss: 1.6298, Accuracy: 83.12%\n17449.4s 9301 ---------------------------\n17449.4s 9302 Epoch 159\n17557.5s 9303 Loss: 1.6315, Accuracy: 82.89%\n17557.5s 9304 ---------------------------\n17557.5s 9305 Epoch 160\n17667.4s 9306 Loss: 1.6265, Accuracy: 83.38%\n17667.4s 9307 saved at /kaggle/working/cnnnet_epoch_160.pth\n17667.4s 9308 ---------------------------\n17667.4s 9309 Epoch 161\n17778.0s 9310 Loss: 1.6477, Accuracy: 81.33%\n17778.0s 9311 ---------------------------\n17778.0s 9312 Epoch 162\n17888.2s 9313 Loss: 1.6473, Accuracy: 81.33%\n17888.2s 9314 ---------------------------\n17888.2s 9315 Epoch 163\n17997.8s 9316 Loss: 1.6353, Accuracy: 82.56%\n17997.8s 9317 ---------------------------\n17997.8s 9318 Epoch 164\n18106.8s 9319 Loss: 1.6492, Accuracy: 81.14%\n18106.8s 9320 ---------------------------\n18106.8s 9321 Epoch 165\n18216.0s 9322 Loss: 1.6286, Accuracy: 83.26%\n18216.0s 9323 ---------------------------\n18216.0s 9324 Epoch 166\n18325.0s 9325 Loss: 1.6329, Accuracy: 82.95%\n18325.0s 9326 ---------------------------\n18325.0s 9327 Epoch 167\n18434.1s 9328 Loss: 1.6481, Accuracy: 81.29%\n18434.1s 9329 ---------------------------\n18434.1s 9330 Epoch 168\n18543.3s 9331 Loss: 1.6259, Accuracy: 83.49%\n18543.3s 9332 ---------------------------\n18543.3s 9333 Epoch 169\n18652.9s 9334 Loss: 1.6209, Accuracy: 83.95%\n18652.9s 9335 ---------------------------\n18652.9s 9336 Epoch 170\n18762.8s 9337 Loss: 1.6117, Accuracy: 84.89%\n18762.8s 9338 ---------------------------\n18762.8s 9339 Epoch 171\n18872.3s 9340 Loss: 1.6060, Accuracy: 85.55%\n18872.3s 9341 ---------------------------\n18872.3s 9342 Epoch 172\n18980.9s 9343 Loss: 1.6015, Accuracy: 85.95%\n18980.9s 9344 ---------------------------\n18980.9s 9345 Epoch 173\n19089.2s 9346 Loss: 1.6214, Accuracy: 83.99%\n19089.2s 9347 ---------------------------\n19089.2s 9348 Epoch 174\n19199.2s 9349 Loss: 1.6227, Accuracy: 83.82%\n19199.2s 9350 ---------------------------\n19199.2s 9351 Epoch 175\n19309.1s 9352 Loss: 1.6113, Accuracy: 85.01%\n19309.1s 9353 ---------------------------\n19309.1s 9354 Epoch 176\n19418.8s 9355 Loss: 1.6021, Accuracy: 85.89%\n19418.8s 9356 ---------------------------\n19418.8s 9357 Epoch 177\n19528.6s 9358 Loss: 1.6007, Accuracy: 86.02%\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Inference block\n\nclass_mapping = [\n    \"air_conditioner\",\n    \"car_horn\",\n    \"children_playing\",\n    \"dog_bark\",\n    \"drilling\",\n    \"engine_idling\",\n    \"gun_shot\",\n    \"jackhammer\",\n    \"siren\",\n    \"street_music\"\n]\n\n\ndef predict(model, input, target, class_mapping):\n    model.eval()\n    with torch.no_grad():\n        predictions = model(input)\n        # Tensor (1, 10) -> [ [0.1, 0.01, ..., 0.6] ]\n        predicted_index = predictions[0].argmax(0)\n        predicted = class_mapping[predicted_index]\n        expected = class_mapping[target]\n    return predicted, expected\n\n\nif __name__ == \"__main__\":\n    # loads back the model\n    cnn = CNNNetwork()\n    state_dict = torch.load(\"/kaggle/input/trained-model-data/cnnnet_epoch_160.pth\", map_location=torch.device('cpu'))\n    cnn.load_state_dict(state_dict)\n\n    # loads urban sound dataset dataset\n    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n        sample_rate=SAMPLE_RATE,\n        n_fft=1024,\n        hop_length=512,\n        n_mels=64\n    )\n\n    usd = UrbanSoundDataset(ANNOTATIONS_FILE,\n                            AUDIO_DIR,\n                            mel_spectrogram,\n                            SAMPLE_RATE,\n                            NUM_SAMPLES,\n                            \"cpu\")\n    \n    correct_predictions = 0\n    total_samples = 0\n\n    for i in range(len(usd) - 1742, len(usd)):\n        input, target = usd[i][0], usd[i][1]\n        input = input.unsqueeze(0)\n        cnn.eval()\n        with torch.no_grad():\n            predictions = cnn(input)\n            predicted_index = predictions[0].argmax(0)\n            # Maps indices to class names\n            predicted = class_mapping[predicted_index.item()]\n            expected = class_mapping[target.item()]\n            if predicted == expected:\n                correct_predictions += 1\n\n            total_samples += 1\n\n    # Calculates overall accuracy\n    accuracy = correct_predictions / total_samples\n    print(f\"Overall accuracy on the last 1742 samples: {accuracy*100:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-09T19:40:39.763402Z","iopub.execute_input":"2024-08-09T19:40:39.764422Z","iopub.status.idle":"2024-08-09T19:42:28.936964Z","shell.execute_reply.started":"2024-08-09T19:40:39.764350Z","shell.execute_reply":"2024-08-09T19:42:28.935947Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Overall accuracy on the last 1742 samples: 59.3571\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}