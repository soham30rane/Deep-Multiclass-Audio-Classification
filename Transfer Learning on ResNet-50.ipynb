{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9900,"sourceType":"datasetVersion","datasetId":6209},{"sourceId":15444,"sourceType":"datasetVersion","datasetId":11102},{"sourceId":9157202,"sourceType":"datasetVersion","datasetId":5532072},{"sourceId":192284858,"sourceType":"kernelVersion"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch.optim as optim\nimport torch.nn.functional as F\n# from torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import models\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\n\nfrom PIL import Image, ImageDraw\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\n# import time\nimport cv2\nimport os\n","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:19:06.889632Z","iopub.execute_input":"2024-08-12T17:19:06.889974Z","iopub.status.idle":"2024-08-12T17:19:13.467843Z","shell.execute_reply.started":"2024-08-12T17:19:06.889945Z","shell.execute_reply":"2024-08-12T17:19:13.466972Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input/cifar10-python'):\n    for foldername in _:\n        print(os.path.join(dirname, foldername))\n        break","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:19:19.951321Z","iopub.execute_input":"2024-08-12T17:19:19.951850Z","iopub.status.idle":"2024-08-12T17:19:19.970373Z","shell.execute_reply.started":"2024-08-12T17:19:19.951812Z","shell.execute_reply":"2024-08-12T17:19:19.969571Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/cifar10-python/cifar-10-batches-py\n","output_type":"stream"}]},{"cell_type":"code","source":"# transform = transforms.Compose([\n# #     [transforms.RandomResizedCrop(255),\n# #      transforms.CenterCrop(224),  \n#      transforms.Resize(size=(150 , 150)) ,\n#      transforms.ColorJitter(0.4,0.5,0.5,0.2),\n#      transforms.RandomHorizontalFlip(p=0.5) , \n#      transforms.RandomCrop(size=(150,150)),  \n    \n#      transforms.ToTensor(),\n#      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n\ntrain_transforms = transforms.Compose([\n    transforms.Resize(size=(150 , 150)) ,\n     transforms.ColorJitter(0.4,0.5,0.5,0.2),\n     transforms.RandomHorizontalFlip(p=0.4) , \n     transforms.RandomCrop(size=(150,150)),     \n     transforms.ToTensor(),\n     transforms.Normalize((0.425, 0.415, 0.405), (0.205, 0.205, 0.205))])\n\n\ntest_transforms = transforms.Compose([\n    transforms.Resize((150, 150)),      \n    transforms.ToTensor(),\n    transforms.Normalize((0.425, 0.415, 0.405), (0.255, 0.245, 0.235))\n])\n\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=train_transforms)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=test_transforms)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=32,\n                                         shuffle=False, num_workers=2)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:19:21.484713Z","iopub.execute_input":"2024-08-12T17:19:21.485311Z","iopub.status.idle":"2024-08-12T17:19:26.531760Z","shell.execute_reply.started":"2024-08-12T17:19:21.485277Z","shell.execute_reply":"2024-08-12T17:19:26.531010Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:01<00:00, 99712533.55it/s] \n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"train_len=len(trainset)\ntest_len=len(testset)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:19:31.895128Z","iopub.execute_input":"2024-08-12T17:19:31.895601Z","iopub.status.idle":"2024-08-12T17:19:31.901186Z","shell.execute_reply.started":"2024-08-12T17:19:31.895560Z","shell.execute_reply":"2024-08-12T17:19:31.899842Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(test_len)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:19:33.763762Z","iopub.execute_input":"2024-08-12T17:19:33.764350Z","iopub.status.idle":"2024-08-12T17:19:33.768671Z","shell.execute_reply.started":"2024-08-12T17:19:33.764319Z","shell.execute_reply":"2024-08-12T17:19:33.767791Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"10000\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(trainset.classes))\n\ntrainset.classes\n# same classes in test data ","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:19:34.859454Z","iopub.execute_input":"2024-08-12T17:19:34.860394Z","iopub.status.idle":"2024-08-12T17:19:34.868591Z","shell.execute_reply.started":"2024-08-12T17:19:34.860355Z","shell.execute_reply":"2024-08-12T17:19:34.867379Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"10\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['airplane',\n 'automobile',\n 'bird',\n 'cat',\n 'deer',\n 'dog',\n 'frog',\n 'horse',\n 'ship',\n 'truck']"},"metadata":{}}]},{"cell_type":"code","source":"model = models.resnet50(pretrained=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:19:36.444916Z","iopub.execute_input":"2024-08-12T17:19:36.445509Z","iopub.status.idle":"2024-08-12T17:19:37.734786Z","shell.execute_reply.started":"2024-08-12T17:19:36.445457Z","shell.execute_reply":"2024-08-12T17:19:37.733844Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 164MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"# for param in model.parameters(): # freezes the layers\n#     param.required_grad = False\n# number_feature = model.fc.in_features\n# model.fc = torch.nn.Linear(in_features=number_feature , out_features=10, bias=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:19:39.105646Z","iopub.execute_input":"2024-08-12T17:19:39.106021Z","iopub.status.idle":"2024-08-12T17:19:39.110032Z","shell.execute_reply.started":"2024-08-12T17:19:39.105991Z","shell.execute_reply":"2024-08-12T17:19:39.109119Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Freeze all layers except the final classification layer\nfor name, param in model.named_parameters():\n    if \"fc\" in name:  # Unfreeze the final classification layer\n        param.requires_grad = True\n    else:\n        param.requires_grad = False\n","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:19:41.006652Z","iopub.execute_input":"2024-08-12T17:19:41.007004Z","iopub.status.idle":"2024-08-12T17:19:41.012773Z","shell.execute_reply.started":"2024-08-12T17:19:41.006976Z","shell.execute_reply":"2024-08-12T17:19:41.011795Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('device is ', device)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:19:42.759717Z","iopub.execute_input":"2024-08-12T17:19:42.760096Z","iopub.status.idle":"2024-08-12T17:19:42.812447Z","shell.execute_reply.started":"2024-08-12T17:19:42.760066Z","shell.execute_reply":"2024-08-12T17:19:42.811401Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"device is  cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:19:44.315544Z","iopub.execute_input":"2024-08-12T17:19:44.316346Z","iopub.status.idle":"2024-08-12T17:19:44.541243Z","shell.execute_reply.started":"2024-08-12T17:19:44.316315Z","shell.execute_reply":"2024-08-12T17:19:44.540282Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer=optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\nschedul_learning = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizer , milestones=[3 , 6 ] ,\n                                                        gamma=0.5)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:20:19.680525Z","iopub.execute_input":"2024-08-12T17:20:19.681217Z","iopub.status.idle":"2024-08-12T17:20:19.687441Z","shell.execute_reply.started":"2024-08-12T17:20:19.681182Z","shell.execute_reply":"2024-08-12T17:20:19.686418Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model.train()\n    \nfor epoch in range(20):\n    total_correct = 0.0 \n    running_loss = 0.0 \n    for i, (inputs, labels) in enumerate(trainloader):\n        inputs, labels = inputs.cuda(), labels.cuda()\n        # Forward pass\n        output = model(inputs)\n        # Get predicted classes\n        output_idex = torch.argmax(output, dim=1)\n        # Calculate the number of correct predictions\n        total_correct += (labels == output_idex).sum().item()\n        # Zero the parameter gradients\n        optimizer.zero_grad()\n        # Calculate loss\n        loss = criterion(output, labels)  # Fixed typo: 'cirterion' to 'criterion'\n        running_loss += loss.item() * inputs.size(0)\n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n    print('epoch: ', epoch, 'loss: ', running_loss / train_len, 'accuracy: ', (total_correct / train_len) * 100, '%')\n\n    if (epoch + 1) % 3 == 0:\n            Data_Snapshot = f'/kaggle/working/cnnnet_epoch_{epoch+1}.pth'\n            torch.save(model.state_dict(), Data_Snapshot)\n            print(f\" saved at {Data_Snapshot}\")\n    print(\"---------------------------\")\n\nprint('finished training')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-12T17:20:22.613997Z","iopub.execute_input":"2024-08-12T17:20:22.614599Z","iopub.status.idle":"2024-08-12T17:57:23.501765Z","shell.execute_reply.started":"2024-08-12T17:20:22.614558Z","shell.execute_reply":"2024-08-12T17:57:23.500679Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"epoch:  0 loss:  1.0146068847465515 accuracy:  66.704 %\n---------------------------\nepoch:  1 loss:  0.7963647353076935 accuracy:  72.76599999999999 %\n---------------------------\nepoch:  2 loss:  0.7743401646614074 accuracy:  73.76 %\n saved at /kaggle/working/cnnnet_epoch_3.pth\n---------------------------\nepoch:  3 loss:  0.7466917690753937 accuracy:  74.276 %\n---------------------------\nepoch:  5 loss:  0.7228994320201874 accuracy:  75.234 %\n saved at /kaggle/working/cnnnet_epoch_6.pth\n---------------------------\nepoch:  6 loss:  0.7195748014545441 accuracy:  75.468 %\n---------------------------\nepoch:  7 loss:  0.7127152788257599 accuracy:  75.554 %\n---------------------------\nepoch:  8 loss:  0.7048812763404846 accuracy:  75.928 %\n saved at /kaggle/working/cnnnet_epoch_9.pth\n---------------------------\nepoch:  9 loss:  0.6917364977455139 accuracy:  76.266 %\n---------------------------\nepoch:  10 loss:  0.6951166493034363 accuracy:  76.294 %\n---------------------------\nepoch:  11 loss:  0.6932430562496186 accuracy:  76.414 %\n saved at /kaggle/working/cnnnet_epoch_12.pth\n---------------------------\nepoch:  12 loss:  0.6938887001800537 accuracy:  76.346 %\n---------------------------\nepoch:  16 loss:  0.6774496854972839 accuracy:  76.88000000000001 %\n---------------------------\nepoch:  17 loss:  0.6849525020980834 accuracy:  76.766 %\n saved at /kaggle/working/cnnnet_epoch_18.pth\n---------------------------\nepoch:  18 loss:  0.6732319131088257 accuracy:  77.008 %\n---------------------------\nepoch:  19 loss:  0.673291750459671 accuracy:  77.03999999999999 %\n---------------------------\nfinished training\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test\n\nwith torch.no_grad():\n    model.eval()\n    total_loss=0.0 \n    total_correct=0.0 \n    for inputs, labels in testloader:\n        labels=labels.to(device)\n        outputs=model(inputs.to(device))\n        loss=criterion(outputs, labels)\n        total_loss+=loss.item()*inputs.size(0)\n        output_idx=torch.argmax(outputs, dim=1)\n        total_correct+=sum(labels==output_idx).sum().item() \n        accuracy = (total_correct / test_len) * 100\n        loss = total_loss / test_len\n\n    print(f'Accuracy: {accuracy:.2f}% Loss: {loss:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-08-12T19:06:55.870928Z","iopub.execute_input":"2024-08-12T19:06:55.871292Z","iopub.status.idle":"2024-08-12T19:07:12.175995Z","shell.execute_reply.started":"2024-08-12T19:06:55.871252Z","shell.execute_reply":"2024-08-12T19:07:12.174879Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Accuracy: 82.06% Loss: 0.5240\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}